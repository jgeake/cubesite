{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGW5JXhTFW2/EBrAmPfQ9T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# app.py\n","from flask import Flask, request, jsonify\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","\n","app = Flask(__name__)\n","\n","# Load your four pre-trained models\n","model1 = tf.keras.models.load_model('square1.1_model.keras')\n","model2 = tf.keras.models.load_model('square2.1_model.keras')\n","model3 = tf.keras.models.load_model('square3.1_model.keras')\n","model4 = tf.keras.models.load_model('square4.1_model.keras')\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    # Verify that exactly six images were sent\n","    if 'images' not in request.files or len(request.files.getlist('images')) != 6:\n","        return jsonify({'error': 'Please upload exactly six images.'}), 400\n","\n","    # Get all six images from the request\n","    images = request.files.getlist('images')\n","\n","    # Process and predict for each image with each model\n","    predictions = {}\n","    for i, file in enumerate(images):\n","        image = Image.open(file)\n","        processed_image = preprocess_image(image)\n","\n","        # Run predictions with each model on the processed image\n","        predictions[f'image_{i+1}_model1'] = model1.predict(processed_image).tolist()\n","        predictions[f'image_{i+1}_model2'] = model2.predict(processed_image).tolist()\n","        predictions[f'image_{i+1}_model3'] = model3.predict(processed_image).tolist()\n","        predictions[f'image_{i+1}_model4'] = model4.predict(processed_image).tolist()\n","\n","    # Return all predictions as JSON\n","    return jsonify(predictions)\n","\n","def preprocess_image(image):\n","    # Resize and normalize as required by your model\n","    image = image.resize((224, 224))  # Adjust to your model's input size\n","    image = np.array(image) / 255.0\n","    image = np.expand_dims(image, axis=0)  # Add batch dimension\n","    return image\n","\n","if __name__ == '__main__':\n","    app.run(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_-jauG35FCg","executionInfo":{"status":"ok","timestamp":1731609282490,"user_tz":480,"elapsed":284945,"user":{"displayName":"Joel Geake","userId":"15223367573028043296"}},"outputId":"38d65f73-77b5-4c08-9680-3cdf1a5d72f5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive2\n"," * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug: * Restarting with stat\n"]}]}]}